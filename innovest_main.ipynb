{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf10d7f6-50a7-48d6-afb7-5f26f58c698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welcome to InnoVest!\n",
    "\n",
    "print(f'Enjoy reviewing our InnoVest mainframe code!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbaf7f5-e3c3-48d1-8597-73498a4aa49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the story...\n",
    "\n",
    "# Some investors profit by finding stocks that are overvalued or undervalued based on market sentiment. \n",
    "\n",
    "# They use various indicators to measure market sentiment that help determine the best stocks to trade. \n",
    "\n",
    "# Popular sentiment indicators include the Internet Search Activity, Bullish Percent Index (BPI) and moving averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be518b9-eef3-422a-a6b4-0ad722f58ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports & Engines\n",
    "\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from pathlib import Path\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0186c993-da83-48b5-8b67-db61a0ab5561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env environment to ensure all systems go!\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c098be39-2223-412a-b3c1-04dbe4ac575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Alpaca API key and secret\n",
    "\n",
    "alpaca_api_key = os.getenv('ALPACA_API_KEY')\n",
    "alpaca_secret_key = os.getenv('ALPACA_SECRET_KEY')\n",
    "\n",
    "#Create Alpaca API object\n",
    "\n",
    "alpaca_api = tradeapi.REST(\n",
    "    alpaca_api_key,\n",
    "    alpaca_secret_key,\n",
    "    api_version=\"V2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b495aaa6-6619-4a18-a815-9d92895d3e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format start and end dates as ISO format for One Year period\n",
    "\n",
    "start = pd.Timestamp(\"2022-08-02\", tz=\"America/New_York\").isoformat()\n",
    "end = pd.Timestamp(\"2023-08-02\", tz=\"America/New_York\").isoformat()\n",
    "\n",
    "# Configure Data Parameters\n",
    "\n",
    "tickers = ['SPY', 'TSLA', 'LCID', 'F', 'META', 'RBLX', 'AAPL', 'GOOG', 'MSFT', 'NVDA']\n",
    "\n",
    "# Adjusting Timeframe to 1Week instead of 1Day due to Google Trends Data Output\n",
    "\n",
    "timeframe = \"1Week\"\n",
    "\n",
    "# Get closing price market data for specitfically identified 'innovative' stocks, for last year\n",
    "\n",
    "portfolio_year_df = alpaca_api.get_bars(tickers, timeframe, start=start, end=end).df\n",
    "\n",
    "# Clean up data to have information we need and interested in\n",
    "\n",
    "portfolio_year_df.drop(columns=['open', 'high', 'low', 'volume', 'trade_count', 'vwap'], inplace=True)\n",
    "\n",
    "# Show dataframe of closing prices\n",
    "\n",
    "portfolio_year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d4b46-cd59-4042-bdbd-df607947da8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Specific Ticker Information from Dataframe\n",
    "\n",
    "spy_data = portfolio_year_df[portfolio_year_df['symbol'] == 'SPY']\n",
    "tsla_data = portfolio_year_df[portfolio_year_df['symbol'] == 'TSLA']\n",
    "lcid_data = portfolio_year_df[portfolio_year_df['symbol'] == 'LCID']\n",
    "f_data = portfolio_year_df[portfolio_year_df['symbol'] == 'F']\n",
    "meta_data = portfolio_year_df[portfolio_year_df['symbol'] == 'META']\n",
    "rblx_data = portfolio_year_df[portfolio_year_df['symbol'] == 'RBLX']\n",
    "aapl_data = portfolio_year_df[portfolio_year_df['symbol'] == 'AAPL']\n",
    "goog_data = portfolio_year_df[portfolio_year_df['symbol'] == 'GOOG']\n",
    "msft_data = portfolio_year_df[portfolio_year_df['symbol'] == 'MSFT']\n",
    "nvda_data = portfolio_year_df[portfolio_year_df['symbol'] == 'NVDA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d47e2e4-4300-4061-9285-33c3754cb464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Clean Separate Ticker Data\n",
    "\n",
    "meta_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b21505-efb8-4a06-b1ae-d230c89539f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose specific Stock Close (Pricing) information column and get Daily Returns\n",
    "\n",
    "spy_daily_returns = spy_data['close'].pct_change()\n",
    "tsla_daily_returns = tsla_data['close'].pct_change()\n",
    "lcid_daily_returns = lcid_data['close'].pct_change()\n",
    "f_daily_returns = f_data['close'].pct_change()\n",
    "meta_daily_returns = meta_data['close'].pct_change()\n",
    "rblx_daily_returns = rblx_data['close'].pct_change()\n",
    "aapl_daily_returns = aapl_data['close'].pct_change()\n",
    "goog_daily_returns = goog_data['close'].pct_change()\n",
    "msft_daily_returns = msft_data['close'].pct_change()\n",
    "nvda_daily_returns = nvda_data['close'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec885e11-e487-44ba-a477-931511218d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Clean Separate Stock Daily Returns\n",
    "\n",
    "f_daily_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c2ff43-3a70-4ead-bbe9-723d9dc4bca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Daily Returns into Dataframe with all Stocks\n",
    "\n",
    "combined_dly_rtn = pd.concat([spy_daily_returns, tsla_daily_returns, lcid_daily_returns, f_daily_returns, meta_daily_returns, rblx_daily_returns, aapl_daily_returns, goog_daily_returns, msft_daily_returns, nvda_daily_returns], axis=\"columns\", join=\"inner\")\n",
    "\n",
    "# Remame Columns in newly created concatenated Daily Returns DataFrame\n",
    "\n",
    "combined_dly_rtn.columns = [\"SPY\", \"TSLA\", \"LCID\", \"F\", \"META\", \"RBLX\", \"AAPL\", \"GOOG\", \"MSFT\", \"NVDA\"]\n",
    "\n",
    "# Show cleaned up, individual stock Daily Returns together\n",
    "\n",
    "combined_dly_rtn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d81ae65-2c85-4db9-8475-a56fbb51fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up to show info for corresponding stocks and group them by sectors in Cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5909df-83f7-4236-96fe-0667f1677924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Electric Vehicles\n",
    "\n",
    "print('Here are the best EV stocks risk indicators:')\n",
    "print('')\n",
    "\n",
    "# TSLA \n",
    "\n",
    "print(f'This is the information for TSLA:')\n",
    "print('')\n",
    "tsla_covariance = combined_dly_rtn['TSLA'].cov(combined_dly_rtn['SPY'])\n",
    "print(f'The covariance is {tsla_covariance}.')\n",
    "\n",
    "tsla_variance = combined_dly_rtn['SPY'].var()\n",
    "print(f'The variance is {tsla_variance}.')\n",
    "\n",
    "tsla_beta = tsla_covariance / tsla_variance\n",
    "print(f'The beta for $TSLA is {tsla_beta}.')\n",
    "\n",
    "print('')\n",
    "# 'LCID'\n",
    "\n",
    "print(f'This is the information for LCID:')\n",
    "print('')\n",
    "\n",
    "lcid_covariance = combined_dly_rtn['LCID'].cov(combined_dly_rtn['SPY'])\n",
    "print(f'The covariance is {lcid_covariance}.')\n",
    "\n",
    "lcid_variance = combined_dly_rtn['SPY'].var()\n",
    "print(f'The variance is {lcid_variance}.')\n",
    "\n",
    "lcid_beta = lcid_covariance / lcid_variance\n",
    "print(f'The beta for $LCID is {lcid_beta}.')\n",
    "print('')\n",
    "\n",
    "# 'F'\n",
    "\n",
    "print(f'This is the information for F:')\n",
    "print('')\n",
    "\n",
    "f_covariance = combined_dly_rtn['F'].cov(combined_dly_rtn['SPY'])\n",
    "print(f'The covariance is {f_covariance}.')\n",
    "\n",
    "f_variance = combined_dly_rtn['SPY'].var()\n",
    "print(f'The variance is {f_variance}.')\n",
    "\n",
    "f_beta = f_covariance / f_variance\n",
    "print(f'The beta for $F is {f_beta}.')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b7cdc9-1655-46db-9509-494c1de3f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metaverse\n",
    "\n",
    "print('Here are the best Metaverse stocks risk indicators:')\n",
    "print('')\n",
    "\n",
    "# 'META'\n",
    "\n",
    "print(f'This is the information for META:')\n",
    "print('')\n",
    "\n",
    "meta_covariance = combined_dly_rtn['META'].cov(combined_dly_rtn['SPY'])\n",
    "print(f'The covariance is {meta_covariance}.')\n",
    "\n",
    "meta_variance = combined_dly_rtn['SPY'].var()\n",
    "print(f'The variance is {meta_variance}.')\n",
    "\n",
    "meta_beta = meta_covariance / meta_variance\n",
    "print(f'The beta for $META is {meta_beta}.')\n",
    "print('')\n",
    "\n",
    "# 'RBLX'\n",
    "\n",
    "print(f'This is the information for RBLX:')\n",
    "print('')\n",
    "\n",
    "rblx_covariance = combined_dly_rtn['RBLX'].cov(combined_dly_rtn['SPY'])\n",
    "print(f'The covariance is {rblx_covariance}.')\n",
    "\n",
    "rblx_variance = combined_dly_rtn['SPY'].var()\n",
    "print(f'The variance is {rblx_variance}.')\n",
    "\n",
    "rblx_beta = rblx_covariance / rblx_variance\n",
    "print(f'The beta for $RBLX is {rblx_beta}.')\n",
    "print('')\n",
    "\n",
    "# 'AAPL'\n",
    "\n",
    "print(f'This is the information for AAPL:')\n",
    "print('')\n",
    "\n",
    "aapl_covariance = combined_dly_rtn['AAPL'].cov(combined_dly_rtn['SPY'])\n",
    "print(f'The covariance is {aapl_covariance}.')\n",
    "\n",
    "aapl_variance = combined_dly_rtn['SPY'].var()\n",
    "print(f'The variance is {aapl_variance}.')\n",
    "\n",
    "aapl_beta = aapl_covariance / aapl_variance\n",
    "print(f'The beta for $AAPL is {aapl_beta}.')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aa3a35-b757-40bb-bedb-8d9c0a9e742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificial Intelligence Stocks\n",
    "\n",
    "print('Here are the best Artificial Intelligence stocks risk indicators:')\n",
    "print('')\n",
    "\n",
    "# 'GOOG'\n",
    "\n",
    "print(f'This is the information for GOOG:')\n",
    "print('')\n",
    "\n",
    "goog_covariance = combined_dly_rtn['GOOG'].cov(combined_dly_rtn['SPY'])\n",
    "print(f'The covariance is {goog_covariance}.')\n",
    "\n",
    "goog_variance = combined_dly_rtn['SPY'].var()\n",
    "print(f'The variance is {goog_variance}.')\n",
    "\n",
    "goog_beta = goog_covariance / goog_variance\n",
    "print(f'The beta for $GOOG is {goog_beta}.')\n",
    "print('')\n",
    "\n",
    "# 'MSFT'\n",
    "print(f'This is the information for MSFT:')\n",
    "print('')\n",
    "\n",
    "msft_covariance = combined_dly_rtn['MSFT'].cov(combined_dly_rtn['SPY'])\n",
    "print(f'The covariance is {msft_covariance}.')\n",
    "\n",
    "msft_variance = combined_dly_rtn['SPY'].var()\n",
    "print(f'The variance is {msft_variance}.')\n",
    "\n",
    "msft_beta = msft_covariance / msft_variance\n",
    "print(f'The beta for $MSFT is {msft_beta}.')\n",
    "print('')\n",
    "\n",
    "# 'NVDA'\n",
    "\n",
    "print(f'This is the information for NVDA:')\n",
    "print('')\n",
    "\n",
    "nvda_covariance = combined_dly_rtn['NVDA'].cov(combined_dly_rtn['SPY'])\n",
    "print(f'The covariance is {nvda_covariance}.')\n",
    "\n",
    "nvda_variance = combined_dly_rtn['SPY'].var()\n",
    "print(f'The variance is {nvda_variance}.')\n",
    "\n",
    "nvda_beta = nvda_covariance / nvda_variance\n",
    "print(f'The beta for $NVDA is {nvda_beta}.')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42331fa-09a0-4c0e-a2a2-bd57301678fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate specific stocks to show Daily Returns for that particular innovative sector in future recommended portfolio\n",
    "\n",
    "ev_port_daily = combined_dly_rtn.iloc[:,1:4]\n",
    "meta_port_daily = combined_dly_rtn.iloc[:,4:7]\n",
    "ai_port_daily = combined_dly_rtn.iloc[:,6:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687b60e0-7ceb-4ebd-9538-72f573277033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does it work?\n",
    "\n",
    "ai_port_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f19d47-6a5a-4a2f-bbed-e7f058e0b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Code showing Annualized Standard Deviation\n",
    "\n",
    "daily_std = combined_dly_rtn.std()\n",
    "\n",
    "# Identify the stock with the most risk\n",
    "\n",
    "daily_std = combined_dly_rtn.std().sort_values()\n",
    "\n",
    "# Calculate the annualized standard deviation (52 weeks for each week of data)\n",
    "\n",
    "annualized_std = daily_std * np.sqrt(52)\n",
    "\n",
    "# What's the story here?\n",
    "\n",
    "print('')\n",
    "print(f'Standard deviation is useful for measuring the absolute risk of an asset or a portfolio, regardless of the market or benchmark.') \n",
    "print('')\n",
    "print(f'It helps investors to assess the potential range of outcomes and the probability of achieving a certain return.')\n",
    "print('')\n",
    "\n",
    "annualized_std.hvplot.bar(xlabel='Stock Ticker $', ylabel='Annualized Standard Deviation', title='Volatility', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764aaf4f-e307-4405-8fab-2fbe4c9c7deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equal Distribution of Stock Concentration \n",
    "# Will configure stock to later show to show potential returns, with specific initial dollar ivestment amount, based on your risk tolerance\n",
    "\n",
    "initial_investment = 10000\n",
    "weight = [.1, .1, .1, .1, .1, .1, .1, .1, .1, .1]\n",
    "\n",
    "portfolio_returns = combined_dly_rtn.dot(weight)\n",
    "\n",
    "cumulative_returns = (1 + portfolio_returns).cumprod()\n",
    "(initial_investment * cumulative_returns).hvplot(xlabel='A Year Ago Today', ylabel='Portfolio Valuation in $USD', title='Equal Weighted Portfolio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf777ec4-6786-4f43-8745-7f08bab8a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Library or Tools to be used here\n",
    "\n",
    "# Import NEW libraries\n",
    "\n",
    "# Make sure you download required libs and resources by using 'pip install pyfolio-reloaded' in your Terminal/Command Prompt/Anaconda Prompt\n",
    "\n",
    "import pyfolio as pf\n",
    "import riskfolio as rp\n",
    "from empyrial import empyrial, Engine\n",
    "import yfinance as yf\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96544b6a-060f-49d2-991c-82bc60976de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out new Libraries Space\n",
    "\n",
    "tesla_stock_history = pf.utils.get_symbol_rets('TSLA')\n",
    "tesla_stock_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cfefcf-0d9b-4969-864c-7af283be14cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "pf.create_returns_tear_sheet(tesla_stock_history, live_start_date='2022-08-01')\n",
    "\n",
    "names = ['SPY', 'TSLA', 'LCID', 'F']\n",
    "start_date = '2022-08-01'\n",
    "end_date = '2023-08-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b87b2ba-1028-4e84-bc9c-959b6f2dc879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "import riskfolio as rp\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.float_format = '{:.4%}'.format\n",
    "\n",
    "# Date range\n",
    "start = '2022-08-01'\n",
    "end = '2023-08-01'\n",
    "\n",
    "# Tickers of assets\n",
    "assets = ['LCID', 'TSLA', 'F', 'META', 'RBLX', 'AAPL', 'MSFT',\n",
    "          'GOOGL', 'NVDA']\n",
    "assets.sort()\n",
    "\n",
    "# Downloading data\n",
    "data = yf.download(assets, start = start, end = end)\n",
    "data = data.loc[:,('Adj Close', slice(None))]\n",
    "data.columns = assets\n",
    "\n",
    "# Calculating Daily returns\n",
    "\n",
    "Y = data[assets].iloc[-252:,:].pct_change().dropna()\n",
    "\n",
    "display(Y.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4035bd-0f43-4a61-94ca-0584b9fbdac7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tickers of factors\n",
    "\n",
    "factors = ['MTUM', 'QUAL', 'VLUE', 'SIZE', 'USMV']\n",
    "factors.sort()\n",
    "\n",
    "tickers = assets + factors\n",
    "tickers.sort()\n",
    "\n",
    "# Downloading data\n",
    "\n",
    "data = yf.download(tickers, start = start, end = end)\n",
    "data = data.loc[:,('Adj Close', slice(None))]\n",
    "data.columns = tickers\n",
    "\n",
    "# Calculating returns\n",
    "\n",
    "X = data[factors].pct_change().dropna()\n",
    "Y = data[assets].pct_change().dropna()\n",
    "\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7308d455-a67f-4f34-90e8-2a504d4f0208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bringing in Portfolio Data\n",
    "\n",
    "port = rp.Portfolio(returns=Y)\n",
    "\n",
    "# Process to calculate optimal portfolio\n",
    "\n",
    "# Select method and estimate input parameters:\n",
    "\n",
    "method_mu='hist' # Method to estimate expected returns based on historical data.\n",
    "method_cov='hist' # Method to estimate covariance matrix based on historical data.\n",
    "\n",
    "port.assets_stats(method_mu=method_mu, method_cov=method_cov, d=0.94)\n",
    "\n",
    "# Estimate/simulate a optimal portfolio with MINIMAL RISK:\n",
    "\n",
    "model='Classic' # Could be Classic (historical), BL (Black Litterman) or FM (Factor Model)\n",
    "rm = 'MV' # Risk measure used, this time will be variance\n",
    "obj = 'MinRisk' # Objective function, could be MinRisk, MaxRet, Utility or Sharpe\n",
    "hist = True # Use historical scenarios for risk measures that depend on scenarios\n",
    "rf = 0 # Risk free rate\n",
    "l = 0 # Risk aversion factor, only useful when obj is 'Utility'\n",
    "\n",
    "w = port.optimization(model=model, rm=rm, obj=obj, rf=rf, l=l, hist=hist)\n",
    "\n",
    "# Show Optimal Allocation of Best Minimal Risk Stocks\n",
    "\n",
    "display(w.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853d015c-cecf-4e5d-87a9-df895c7e01ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting the composition of the optimal portfolio for risk-adverse/conservative investors:\n",
    "\n",
    "ax = rp.plot_pie(w=w, title='Optimal Portfolio Allocation for Minimal Risk', others=.9, nrow=25, cmap = \"tab20\",\n",
    "                 height=6, width=10, ax=None)\n",
    "\n",
    "points = 50 # Number of points of the frontier / similar to simulated amounts in Monte Carlo\n",
    "\n",
    "frontier = port.efficient_frontier(model=model, rm=rm, points=points, rf=rf, hist=hist)\n",
    "\n",
    "# Show first 5 simulations\n",
    "\n",
    "display(frontier.T.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21f5143-c9df-43ae-837a-9e4063e4e42b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting the efficient frontier\n",
    "\n",
    "label = 'Min Risk Adjusted Return Portfolio' # Title of point\n",
    "mu = port.mu # Expected returns\n",
    "cov = port.cov # Covariance matrix\n",
    "returns = port.returns # Returns of the assets\n",
    "\n",
    "ax = rp.plot_frontier(w_frontier=frontier, mu=mu, cov=cov, returns=returns, rm=rm,\n",
    "                      rf=rf, alpha=0.05, cmap='viridis', w=w, label=label,\n",
    "                      marker='*', s=16, c='r', height=6, width=10, ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8890f583-ad7d-4cc2-bcb9-77d1e21a0860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Risk Measures available:\n",
    "#\n",
    "# 'MV': Standard Deviation.\n",
    "# 'MAD': Mean Absolute Deviation.\n",
    "# 'MSV': Semi Standard Deviation.\n",
    "# 'FLPM': First Lower Partial Moment (Omega Ratio).\n",
    "# 'SLPM': Second Lower Partial Moment (Sortino Ratio).\n",
    "# 'CVaR': Conditional Value at Risk.\n",
    "# 'EVaR': Entropic Value at Risk.\n",
    "# 'WR': Worst Realization (Minimax)\n",
    "# 'MDD': Maximum Drawdown of uncompounded cumulative returns (Calmar Ratio).\n",
    "# 'ADD': Average Drawdown of uncompounded cumulative returns.\n",
    "# 'CDaR': Conditional Drawdown at Risk of uncompounded cumulative returns.\n",
    "# 'EDaR': Entropic Drawdown at Risk of uncompounded cumulative returns.\n",
    "# 'UCI': Ulcer Index of uncompounded cumulative returns.\n",
    "\n",
    "rms = ['MV', 'MAD', 'MSV', 'FLPM', 'SLPM', 'CVaR',\n",
    "       'EVaR', 'WR', 'MDD', 'ADD', 'CDaR', 'UCI', 'EDaR']\n",
    "\n",
    "w_s = pd.DataFrame([])\n",
    "\n",
    "for i in rms:\n",
    "    w = port.optimization(model=model, rm=i, obj=obj, rf=rf, l=l, hist=hist)\n",
    "    w_s = pd.concat([w_s, w], axis=1)\n",
    "    \n",
    "w_s.columns = rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d936b199-b5ec-4942-8883-01103ba867d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w_s.style.format(\"{:.2%}\").background_gradient(cmap='YlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f907c-d6fc-400f-83a7-0102159dac51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global Efficient\n",
    "\n",
    "# The efficient frontier is the set of optimal portfolios that offer the highest expected return for a defined level of risk or the lowest risk for a given level of expected return. (Source: Investopedia)\n",
    "\n",
    "from empyrial import empyrial, Engine\n",
    "\n",
    "most_efficient = Engine(\n",
    "      start_date = \"2022-08-01\",\n",
    "      benchmark = [\"SPY\"], #SPY is set by default\n",
    "      portfolio = [\"LCID\", \"TSLA\", \"F\", \"META\", \"RBLX\", \"AAPL\", \"MSFT\", \"GOOG\", \"NVDA\"],\n",
    "      optimizer = \"EF\" # This designates the Efficient Frontier analysis we're asking for\n",
    ")\n",
    "\n",
    "# Run and show Portfolio Optimization for Global Efficiency amongst Innovative Stocks\n",
    "\n",
    "empyrial(most_efficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e8dfb-fce3-4fb6-ab78-98b0b061fb9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Market Data from August 1st, 2022 until Present Day \n",
    "\n",
    "# Equally Distributed Portfolio of all Innovative Stocks and how a portfolio would perform\n",
    "\n",
    "from empyrial import empyrial, Engine\n",
    "\n",
    "all_nine = Engine(\n",
    "    start_date = \"2022-08-01\", \n",
    "    portfolio = [\"LCID\", \"TSLA\", \"F\", \"META\", \"RBLX\", \"AAPL\", \"MSFT\", \"GOOG\", \"NVDA\"], \n",
    "    benchmark = [\"SPY\"]  # SPY is set by default\n",
    "    #weights = #['0.5, 0.5'] or whatever amount you want to designate specific portfolio stock concentrated weights\n",
    ")\n",
    "\n",
    "empyrial(all_nine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a0409-40d8-4820-afca-a629227ed20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a portfolio with data from `quandl`/`yfinance`\n",
    "# Building a portfolio with `build_portfolio()` by downloading relevant data through `quandl`/`yfinance` with stock names, start and end date and column labels\n",
    "# This example only focuses on how to use `build_portfolio()` to get an instance of `Portfolio` by providing a few items of information that is passed on to `quandl`/`yfinance`. For a more exhaustive description of this package and example, please try `Example-Analysis` and `Example-Optimisation`.\n",
    "\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Importing Custom Functions from FinQuest\n",
    "\n",
    "from finquant.portfolio import build_portfolio\n",
    "\n",
    "# To play around yourself with different stocks, here is a short list of companies and their tickers on Yahoo Finance:\n",
    "# d = {0: {'Name':'GOOG', 'Allocation':20},  # Google\n",
    "#      1: {'Name':'AMZN', 'Allocation':33},  # Amazon\n",
    "#      2: {'Name':'MSFT', 'Allocation':18},  # Microsoft\n",
    "\n",
    "d = {\n",
    "    0: {\"Name\": \"LCID\", \"Allocation\": 10},\n",
    "    1: {\"Name\": \"RIVN\", \"Allocation\": 10},\n",
    "    2: {\"Name\": \"F\", \"Allocation\": 10},\n",
    "}\n",
    "\n",
    "port_allocation = pd.DataFrame.from_dict(d, orient=\"index\")\n",
    "\n",
    "# In the below example we are using `yfinance` to download stock data. We specify the start and end date of the stock prices to be downloaded.\n",
    "# We also provide the optional parameter `market_index` to download the historical data of a market index. `FinQuant` can use them to calculate the beta parameter, measuring the portfolio's daily volatility compared to the market.\n",
    "\n",
    "# here we set the list of names based on the names in the DataFrame pf_allocation\n",
    "names = port_allocation[\"Name\"].values.tolist()\n",
    "\n",
    "# dates can be set as datetime or string, as shown below:\n",
    "start_date = datetime.datetime(2022, 8, 1)\n",
    "end_date = \"2023-08-01\"\n",
    "\n",
    "# the market index used to compare the portfolio to (in this case S&P 500). If the parameter is omitted, no market comparison will be done\n",
    "market_index = \"^GSPC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5779d04c-5f9a-492c-bdd9-409b253ec8af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# While quandl/yfinance will download lots of different prices for each stock,\n",
    "# e.g. high, low, close, etc, FinQuant will extract the column \"Adj. Close\" (\"Adj Close\" if using yfinance).\n",
    "\n",
    "pf_test = build_portfolio(\n",
    "    names=names,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    data_api=\"yfinance\",\n",
    "    market_index=market_index,\n",
    ")\n",
    "\n",
    "#Show Data\n",
    "\n",
    "pf_test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9800c3a-e8d3-409f-bf24-2d898a6295c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# ## Get data from `quandl`/`yfinance` and build portfolio\n",
    "# First we need to build a pandas.DataFrame that holds relevant data for our portfolio. The minimal information needed are stock names and the amount of money to be invested in them, e.g. Allocation.\n",
    "\n",
    "# the portfolio information DataFrame\n",
    "pf_df = pd.DataFrame(pf_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d596d545-7e3d-4329-80ad-806351e5ac0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(pf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb69cde-594e-4f57-a277-92bc7d735d96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# <codecell>\n",
    "\n",
    "# plotting style:\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "# set line width\n",
    "plt.rcParams[\"lines.linewidth\"] = 2\n",
    "# set font size for titles\n",
    "plt.rcParams[\"axes.titlesize\"] = 14\n",
    "# set font size for labels on axes\n",
    "plt.rcParams[\"axes.labelsize\"] = 12\n",
    "# set size of numbers on x-axis\n",
    "plt.rcParams[\"xtick.labelsize\"] = 10\n",
    "# set size of numbers on y-axis\n",
    "plt.rcParams[\"ytick.labelsize\"] = 10\n",
    "# set figure size\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d594cef-a1ea-4306-aa2d-6719205c3090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# <markdowncell>\n",
    "\n",
    "# ### Get data from disk/file\n",
    "# Here we use `pandas.read_cvs()` method to read in the data.\n",
    "\n",
    "# <codecell>\n",
    "\n",
    "# stock data was previously pulled from quandl and stored in ex1-stockdata.csv\n",
    "# read data from files:\n",
    "\n",
    "# <markdowncell>\n",
    "\n",
    "# # Portfolio optimisation\n",
    "# ## Efficient Frontier\n",
    "# Based on the **Efficient Frontier**, the portfolio can be optimised for\n",
    "#  - minimum volatility\n",
    "#  - maximum Sharpe ratio\n",
    "#  - minimum volatility for a given target return\n",
    "#  - maximum Sharpe ratio for a given target volatility\n",
    "# See below for an example for each optimisation.\n",
    "\n",
    "# <codecell>\n",
    "\n",
    "# if needed, change risk free rate and frequency/time window of the portfolio\n",
    "print(\"pf_test.risk_free_rate = {}\".format(pf_test.risk_free_rate))\n",
    "print(\"pf_test.freq = {}\".format(pf_test.freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8336f334-c013-42a1-96fe-0905995b6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_test.ef_minimum_volatility(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b9a16-58b8-45f2-a662-fb07501737fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optimisation for maximum Sharpe ratio\n",
    "pf_test.ef_maximum_sharpe_ratio(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3df09e7-7bb0-44ba-b144-54a05429b899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# minimum volatility for a given target return of 0.26\n",
    "pf_test.ef_efficient_return(0.26, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73abb383-6dae-4aad-862f-ccead36a1228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# maximum Sharpe ratio for a given target volatility of 0.22\n",
    "pf_test.ef_efficient_volatility(0.22, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2841cc0b-8ba7-4f10-8a47-9717620d509a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ### Manually creating an instance of EfficientFrontier\n",
    "# If required, or preferred, the below code shows how the same is achieved by manually creating an instance of EfficientFrontier, passing it the mean returns and covariance matrix of the previously assembled portfolio.\n",
    "\n",
    "from finquant.efficient_frontier import EfficientFrontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133cb40e-3bcc-49a4-b4d9-bada3ca54d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Computing and visualising the Efficient Frontier\n",
    "# `FinQuant` offers several ways to compute the *Efficient Frontier*.\n",
    "#  Recommended option is through the object `portfolio or pf` with limits of the *Efficient Frontier* being automatically set\n",
    "#  We let `pf` or 'pf_test' and be an instance of `Portfolio`. The following code snippets compute and plot an *Efficient Frontier* of a portfolio, its optimised portfolios and individual stocks within the portfolio.\n",
    "#  - `pf.ef_plot_efrontier()`\n",
    "#  - `pf.ef_plot_optimal_portfolios()`\n",
    "#  - `pf.plot_stocks()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd50adb-702c-4cf0-a65c-960ce19ab29a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating an instance with new library to show EfficientFrontier\n",
    "\n",
    "ef = EfficientFrontier(pf_test.comp_mean_returns(freq=1), pf_test.comp_cov())\n",
    "\n",
    "# optimisation for minimum volatility\n",
    "\n",
    "print(ef.minimum_volatility())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb424f5-b078-4c62-b265-4831da69537e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printing out rationale for Minimum Volatility optimized portfolio\n",
    "\n",
    "(expected_return, volatility, sharpe) = ef.properties(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e122c837-b582-4884-b498-4972b699c77e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## Monte Carlo\n",
    "# Perform a Monte Carlo run to find the portfolio with the minimum volatility and maximum Sharpe Ratio.\n",
    "\n",
    "opt_w, opt_res = pf_test.mc_optimisation(num_trials=5000)\n",
    "pf_test.mc_properties()\n",
    "pf_test.mc_plot_results()\n",
    "\n",
    "# Individual stocks can be added to the plot\n",
    "pf_test.plot_stocks()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d08eb34-5892-41e2-8cc6-a6f37d5cc28f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(opt_res)\n",
    "print()\n",
    "print(opt_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b467fae2-f73a-4546-a951-3846e3526933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Optimisation overlay\n",
    "# ## Overlay of Monte Carlo portfolios and Efficient Frontier solutions\n",
    "\n",
    "# performs and plots results of Monte Carlo run (5000 iterations)\n",
    "opt_w, opt_res = pf_test.mc_optimisation(num_trials=5000)\n",
    "# plots the results of the Monte Carlo optimisation\n",
    "pf_test.mc_plot_results()\n",
    "# plots the Efficient Frontier\n",
    "pf_test.ef_plot_efrontier()\n",
    "# plots optimal portfolios based on Efficient Frontier\n",
    "pf_test.ef.plot_optimal_portfolios()\n",
    "# plots individual plots of the portfolio\n",
    "pf_test.plot_stocks()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeae02e-4e35-4975-8a46-fa0c79d7166c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up Sentimental Trading Dataconfiguration\n",
    "\n",
    "# Configure Resource Folder for csv. downloaded from Google Trends and ingested into Innovest Sentiment Trading Engine\n",
    "\n",
    "electric_file = Path('./Resources/electric_trend.csv')\n",
    "meta_file = Path('./Resources/meta_trend.csv')\n",
    "ai_file = Path('./Resources/ai_trend.csv')\n",
    "\n",
    "electric_trend_csv = pd.read_csv(electric_file, index_col=\"Week\", parse_dates=True, infer_datetime_format=True)\n",
    "meta_trend_csv = pd.read_csv(meta_file, index_col=\"Week\", parse_dates=True, infer_datetime_format=True)\n",
    "ai_trend_csv = pd.read_csv(ai_file, index_col=\"Week\", parse_dates=True, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b511035e-7050-49f6-9a45-d06032337e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate & show all Innovative Sectors into One Big DataFrame\n",
    "\n",
    "trends_df = pd.concat([electric_trend_csv, meta_trend_csv, ai_trend_csv], axis=\"columns\", join=\"inner\")\n",
    "\n",
    "trends_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881aefbd-67a1-478d-9291-b551e675e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify specific trends designated by 'Company Name' + 'Sector Name'\n",
    "\n",
    "tsla_trend = trends_df['Tesla Electric Vehicle']\n",
    "lcid_trend = trends_df['Lucid Electric Vehicle']\n",
    "f_trend = trends_df['Ford Electric Vehicle']\n",
    "meta_trend = trends_df['Facebook Metaverse']\n",
    "rblx_trend = trends_df['Roblox Metaverse']\n",
    "aapl_trend = trends_df['Apple Metaverse']\n",
    "google_trend = trends_df['Google Artificial Intelligence']\n",
    "msft_trend = trends_df['Microsoft Artificial Intelligence']\n",
    "nvda_trend = trends_df['Nvidia Artificial Intelligence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221fb736-31e4-42da-9e1e-22c7c91898b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and show Innovative sector specific trends\n",
    "\n",
    "ev_trends = pd.concat([tsla_trend, lcid_trend, f_trend], axis = 'columns', join='inner')\n",
    "meta_trends = pd.concat([meta_trend, rblx_trend, aapl_trend], axis = 'columns', join='inner')\n",
    "ai_trends = pd.concat([google_trend, msft_trend, nvda_trend], axis = 'columns', join='inner')\n",
    "\n",
    "meta_trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fae47e-2cc6-4e75-988b-c2f1903a6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure functions for future Data Analysis & Data Manipulation\n",
    "\n",
    "# Google Trends Standard Deviation\n",
    "\n",
    "weekly_trends_std  = trends_df.std()\n",
    "\n",
    "annualized_trends_std = weekly_trends_std * np.sqrt(52)\n",
    "\n",
    "annualized_trends_std = annualized_trends_std.sort_values()\n",
    "\n",
    "# Show the plot\n",
    "trend_tbl = annualized_trends_std.hvplot.bar(\n",
    "    xlabel='Company + Sector Name',\n",
    "    ylabel='Annualized Trend Standard Deviation',\n",
    "    title='Company most associated with their Innovation sector (least is best)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11fb956-e919-4415-a99f-9ae004160625",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_std.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5dfc0-8c02-4c9d-a246-84a4665f6cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis Continued\n",
    "\n",
    "print(f'Below, we can see which companies, accompanied by their sector, have what we internally call a \"hype guage\".')\n",
    "print('')\n",
    "print(f'This proprietary data indicator determines how likely/unlikely these companies are to remain \"relavant\" in their breakthrough sector:')\n",
    "print('')\n",
    "\n",
    "display(weekly_trends_std)\n",
    "                \n",
    "print('')\n",
    "print(f'Here is each disruptors ability to remain relevant (on average):')\n",
    "print('')\n",
    "display(ev_trends.hvplot(xlabel='Week #', ylabel='Google Trend Score', title='Google Trends in last 12 Months for Electric Vehicle Companies'))\n",
    "print('')\n",
    "print(f'Based on Google Trends Data, here is each Electric Vehicle company ability to stay relevant in innovative space:')\n",
    "print('')\n",
    "print(ev_trends.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b929f492-780b-4909-8077-06e0ce6837ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe Initialization for specific sectors and pricepoints for future Monte Carlo simulations vs. Sentiment Trading Analysis correlation\n",
    "\n",
    "# `cumprod` function to calculate cumulative returns\n",
    "cumulative_returns = (1 + portfolio_returns).cumprod()\n",
    "cumulative_returns.head()\n",
    "\n",
    "# Configure data to plot out initial investment and cumulative returns on initial investment\n",
    "\n",
    "initial_investment = 10000\n",
    "\n",
    "cumulative_profit = initial_investment * cumulative_returns\n",
    "cumulative_profit.hvplot(xlabel='Last Year', ylabel='Portfolio Return/Valuation in $USD', title='How much money would you have, if you invested $10k last year ago today?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175c718e-327e-4de6-ba87-e17a1d58de75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More Extra Visualizations\n",
    "\n",
    "combined_dly_rtn.hvplot()\n",
    "\n",
    "# Bar Plots that will be used in future Overlay and Data Visualization Manipulation\n",
    "\n",
    "tsla_trend_plot = tsla_trend.hvplot(kind='bar')\n",
    "lcid_trend_plot = lcid_trend.hvplot(kind='bar')\n",
    "f_trend_plot = f_trend.hvplot(kind='bar')\n",
    "meta_trend_plot = meta_trend.hvplot(kind='bar')\n",
    "rblx_trend_plot = rblx_trend.hvplot(kind='bar')\n",
    "aapl_trend_plot = aapl_trend.hvplot(kind='bar')\n",
    "google_trend_plot = google_trend.hvplot(kind='bar')\n",
    "msft_trend_plot = msft_trend.hvplot(kind='bar')\n",
    "nvda_trend_plot = nvda_trend.hvplot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8bfec8-2e25-4f5b-8a38-7c0e526e674a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1176af-8dc9-473d-af6f-56ba213c4b46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print out information and quantities of given portfolio\n",
    "print(pf_test)\n",
    "pf_test.properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e089346-5973-4c38-8109-ae64ae358228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the portfolio stock data, prices DataFrame\n",
    "print(pf_test.data)\n",
    "\n",
    "# the portfolio information DataFrame\n",
    "\n",
    "print(pf_test.portfolio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ab9cf-0ff4-4c4b-a88f-5e63c965d767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sandbox for Experimental Data Manipulation for Alexis\n",
    "\n",
    "print(f'What is up guys?!')\n",
    "\n",
    "names = ['GOOG', 'AMZN', 'MCD', 'DIS']\n",
    "start_date = '2022-08-01'\n",
    "end_date = '2023-08-01'\n",
    "\n",
    "pf_hi = build_portfolio(names=names,\n",
    "                    start_date=start_date,\n",
    "                    end_date=end_date)\n",
    "\n",
    "# performs and plots results of Monte Carlo run (5000 iterations)\n",
    "opt_w, opt_res = pf_hi.mc_optimisation(num_trials=5000)\n",
    "# plots the results of the Monte Carlo optimisation\n",
    "pf_hi.mc_plot_results()\n",
    "# plots the Efficient Frontier\n",
    "pf_hi.ef_plot_efrontier()\n",
    "# plots optimal portfolios based on Efficient Frontier\n",
    "pf_hi.ef.plot_optimal_portfolios()\n",
    "# plots individual plots of the portfolio\n",
    "pf_hi.plot_stocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f428220d-04d4-4d48-b793-94b642d1db15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sandbox for Experimental Data Manipulation for Bryant\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"https://twelve-data1.p.rapidapi.com/technical_indicators\"\n",
    "\n",
    "headers = {\n",
    "\t\"X-RapidAPI-Key\": \"93e9c01dcfmsh13483fcf61474d7p1d64aajsn24ae60812857\",\n",
    "\t\"X-RapidAPI-Host\": \"twelve-data1.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf08218-8953-4f66-878a-d1685701e0d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sandbox for Experimental Data Manipulation for Stephan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e218629-c7dd-4b7e-8e13-199bdf4689b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
